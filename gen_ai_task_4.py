# -*- coding: utf-8 -*-
"""gen ai task 4

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1EyhMKE-ASgxwH4fUcNdtg81kp0yXF8SG
"""

# Step 1: Install TensorFlow and required libraries
!pip install -q tensorflow tensorflow-datasets matplotlib

# Step 2: Import libraries
import tensorflow as tf
import tensorflow_datasets as tfds
import matplotlib.pyplot as plt

# Step 3: Load Dataset (Facades - Corrected)
# The 'facades' dataset is likely a top-level dataset in tfds.
# We will try loading 'facades' directly.
try:
    dataset, info = tfds.load('facades', with_info=True, as_supervised=True)
    train, test = dataset['train'], dataset['test']
    print("Successfully loaded 'facades' dataset.")
except tfds.core.DatasetNotFoundError as e:
    print(f"Error loading 'facades' dataset: {e}")
    print("Please check the available datasets list in the traceback or tfds documentation for the correct dataset name.")
    # If facades isn't available, you might need to find the correct dataset for image-to-image translation.
    # For example, 'cycle_gan' is listed and is for image translation, though it's not specifically facades.
    # You can uncomment the line below and try loading 'cycle_gan' if facades doesn't work,
    # but be aware that the dataset structure might be different.
    # dataset, info = tfds.load('cycle_gan', with_info=True, as_supervised=True)
    # train, test = dataset['train'], dataset['test']


# Step 4: Preprocessing functions
def normalize(input_image, target_image):
    # Ensure image data type is suitable for calculations
    input_image = tf.cast(input_image, tf.float32) / 127.5 - 1
    target_image = tf.cast(target_image, tf.float32) / 127.5 - 1
    return input_image, target_image

# Apply normalization only if the dataset was loaded successfully
if 'train' in locals() and 'test' in locals():
    train = train.map(normalize)
    test = test.map(normalize)
else:
    print("Dataset not loaded, skipping normalization and subsequent steps.")


# Step 5: Define Generator (U-Net)
# Define the generator model using the Functional API or Sequential API
# This part remains the same as the original code
OUTPUT_CHANNELS = 3

generator = tf.keras.Sequential([
    tf.keras.layers.Input(shape=[256,256,3]),
    tf.keras.layers.Conv2D(64, 4, strides=2, padding='same'),
    tf.keras.layers.LeakyReLU(),
    tf.keras.layers.Conv2DTranspose(OUTPUT_CHANNELS, 4, strides=2, padding='same', activation='tanh')
])


# Step 6: Define Discriminator (PatchGAN)
# Define the discriminator model using the Functional API
# This part remains the same as the original code
def build_discriminator():
    inp = tf.keras.layers.Input(shape=[256, 256, 3], name='input_image')
    tar = tf.keras.layers.Input(shape=[256, 256, 3], name='target_image')
    # Concatenate the input and target images channel-wise
    x = tf.keras.layers.concatenate([inp, tar])
    # Apply convolutional layers with LeakyReLU activation
    x = tf.keras.layers.Conv2D(64, 4, strides=2, padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    x = tf.keras.layers.Conv2D(128, 4, strides=2, padding='same')(x)
    x = tf.keras.layers.LeakyReLU()(x)
    # Output layer with a single filter for the discriminator output
    x = tf.keras.layers.Conv2D(1, 4, strides=1, padding='same')(x)
    return tf.keras.Model(inputs=[inp, tar], outputs=x)

# Build the discriminator model
discriminator = build_discriminator()

# Step 7: Losses and Optimizers
# Define the loss function and optimizers for the generator and discriminator
# This part remains the same as the original code
loss_object = tf.keras.losses.BinaryCrossentropy(from_logits=True)

def generator_loss(disc_generated_output, gen_output, target):
    # GAN loss: generator wants to trick the discriminator into thinking generated images are real
    gan_loss = loss_object(tf.ones_like(disc_generated_output), disc_generated_output)
    # L1 loss: generator wants to produce images close to the target image
    l1_loss = tf.reduce_mean(tf.abs(target - gen_output))
    # Total generator loss is a combination of GAN loss and L1 loss (weighted)
    return gan_loss + (100 * l1_loss)

def discriminator_loss(disc_real_output, disc_generated_output):
    # Discriminator loss on real images: wants to classify real images as real (1)
    real_loss = loss_object(tf.ones_like(disc_real_output), disc_real_output)
    # Discriminator loss on generated images: wants to classify generated images as fake (0)
    generated_loss = loss_object(tf.zeros_like(disc_generated_output), disc_generated_output)
    # Total discriminator loss is the sum of real and generated losses
    return real_loss + generated_loss

# Define optimizers for the generator and discriminator
generator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)
discriminator_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)

# Step 8: Training Step
# Define the training step as a TensorFlow function for efficiency
# This part remains the same as the original code
@tf.function
def train_step(input_image, target):
    # Use GradientTape to record operations for automatic differentiation
    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:
        # Generate an output image using the generator
        gen_output = generator(input_image, training=True)

        # Pass real and generated images to the discriminator
        disc_real_output = discriminator([input_image, target], training=True)
        disc_generated_output = discriminator([input_image, gen_output], training=True)

        # Calculate the generator and discriminator losses
        gen_loss = generator_loss(disc_generated_output, gen_output, target)
        disc_loss = discriminator_loss(disc_real_output, disc_generated_output)

    # Calculate gradients for both models
    generator_gradients = gen_tape.gradient(gen_loss, generator.trainable_variables)
    discriminator_gradients = disc_tape.gradient(disc_loss, discriminator.trainable_variables)

    # Apply gradients to update model weights
    generator_optimizer.apply_gradients(zip(generator_gradients, generator.trainable_variables))
    discriminator_optimizer.apply_gradients(zip(discriminator_gradients, discriminator.trainable_variables))

# Step 9: Train Model
# Train the GAN model
import time

EPOCHS = 5  # Increase for better results

# Only proceed with training if the dataset was loaded
if 'train' in locals():
    for epoch in range(EPOCHS):
        start = time.time()
        # Iterate over a subset of the training dataset
        for input_image, target in train.take(100):
            train_step(input_image, target)
        print(f"Epoch {epoch+1} completed in {time.time()-start:.2f} sec")
else:
    print("Skipping training as dataset was not loaded.")

# Step 10: Visualize Output
# Function to generate and display images
def generate_images(model, test_input, tar):
    # Generate a prediction using the model
    prediction = model(test_input, training=False)
    # Create a figure to display the images
    plt.figure(figsize=(15, 5))
    # List of images to display: input, ground truth, prediction
    display_list = [test_input[0], tar[0], prediction[0]]
    # Titles for the images
    title = ['Input Image', 'Ground Truth', 'Predicted Image']
    # Iterate through the images and display them
    for i in range(3):
        plt.subplot(1, 3, i+1)
        plt.title(title[i])
        # De-normalize the images for display by reversing the normalization in Step 4
        # Assumes normalization was to [-1, 1], so reverse is img * 0.5 + 0.5
        plt.imshow((display_list[i] * 0.5 + 0.5))
        plt.axis('off') # Hide the axes
    plt.show() # Display the plot

# Only proceed with visualization if the dataset and generator were loaded
if 'test' in locals() and 'generator' in locals():
    # Generate and display images for one example from the test set
    for inp, tar in test.take(1):
        generate_images(generator, tf.expand_dims(inp, 0), tf.expand_dims(tar, 0))
else:
    print("Skipping visualization as dataset or generator was not loaded.")